---
title: "R Notebook"
output: html_notebook
---


```{r}
library(tidyverse)
library(keras)
```

```{r, message = FALSE, warning=FALSE}
dat_raw = read_csv("./data/data.csv")
dat_raw = dat_raw[, 1:32]
```

```{r}
dat_covar = dat_raw %>% select(-id, -diagnosis)
dat_label = cbind(dat_raw$diagnosis) %>% as.data.frame
```



```{r}
set.seed(123)
index = sample(1:nrow(dat_raw), size = trunc(.8 * nrow(dat_raw)))

train_data   = dat_covar %>% filter(row_number() %in% index)    %>% as.matrix
train_labels = dat_label %>% filter(row_number() %in% index)    %>% .$V1 %>% as.numeric %>% as.array %>% `-`(., 1)
train_labels = to_categorical(train_labels)
test_data    = dat_covar %>% filter(!(row_number() %in% index)) %>% as.matrix
test_labels  = dat_label %>% filter(!(row_number() %in% index)) %>% .$V1 %>% as.numeric %>% as.array %>% `-`(., 1)
test_labels  = to_categorical(test_labels)
```

```{r}
class(train_data)
dim(train_data)
class(train_labels)
dim(train_labels)
```

# Normalize
```{r}
# Test data is *not* used when calculating the mean and std.

# Normalize training data
train_data <- scale(train_data) 

# Use means and standard deviations from training set to normalize test set
col_means_train <- attr(train_data, "scaled:center") 
col_stddevs_train <- attr(train_data, "scaled:scale")
test_data <- scale(test_data, center = col_means_train, scale = col_stddevs_train)

train_data[1, ] # First training sample, normalized
```

```{r}
train_labels %>% head
```

```{r}
train_labels %>% unique
```


# Create the model
```{r}
build_model <- function() {
  
  model <- keras_model_sequential() %>%
    layer_dense(units = 64, activation = "relu", input_shape = dim(train_data)[2]) %>%
    layer_dense(units = 64, activation = "relu") %>%
    layer_dense(units = 2,  activation = 'softmax')
  
  model %>% compile(
    loss = "mse",
    optimizer = optimizer_rmsprop(),
    metrics = list("mean_absolute_error")
  )
  
  model
}

model <- build_model()
model %>% summary()
```

# Training the model

```{r}
# Display training progress by printing a single dot for each completed epoch.
print_dot_callback <- callback_lambda(
  on_epoch_end = function(epoch, logs) {
    if (epoch %% 80 == 0) cat("\n")
    cat(".")
  }
)    

epochs <- 50

# Fit the model and store training stats
history <- model %>% fit(
  train_data,
  train_labels,
  epochs = epochs,
  validation_split = 0.2,
  verbose = 0,
  callbacks = list(print_dot_callback)
)
```

```{r}
library(ggplot2)

plot(history, metrics = "mean_absolute_error", smooth = FALSE) +
  coord_cartesian(ylim = c(0, .3))
```

```{r}
history
```

```{r}
c(loss, mae) %<-% (model %>% evaluate(test_data, test_labels, verbose = 0))
paste0("Mean absolute error on test set: $", sprintf("%.2f", mae * 1000))
```

# Predict
```{r}
test_predictions <- model %>% predict(test_data)
class(test_data)
test_predictions %>% head
```

```{r}
tmp = test_data[1,] %>% rbind
class(tmp)
dim(tmp)
model %>% predict(tmp)
```


```{r}
apply(test_data, 1, function(x){
    x %>% rbind %>% predict_classes(model, .)
}) # end apply
```

ROC curve
```{r}
library(pROC)
```

```{r}
apply(rbind(train_data, test_data), 1, function(x){
    x %>% rbind %>% predict_classes(model, .)
}) # end apply
```

```{r}
c(train_labels[, 2], test_labels[, 2])
```

```{r}
rbind(train_data, test_data) %>% dim
```

```{r}
length(y_true)
length(y_pred)
```

```{r}
concordance <- function(y_true, y_score){
    require(zeallot)
    require(pROC)
    
    # Get all actual observations and their fitted values into a frame
    fitted <- data.frame(cbind(y_true, y_score))
    colnames(fitted)<-c('respvar','score')
    
    # Subset only ones
    ones  <- fitted[fitted[,1] == 1,]
    # Subset only zeros
    zeros <- fitted[fitted[,1] == 0,]
    
    #print(ones)
    #print(zeros)
    # Initialise all the values
    c(paris_tested, conc, disc, ties) %<-% c(0, 0, 0, 0)
    #pairs_tested <- 0
    #conc         <- 0
    #disc         <- 0
    #ties         <- 0
      
    # Get the values in a for-loop
    for(i in 1:nrow(ones)) {
          
        for(j in 1:nrow(zeros)) {
            pairs_tested<-pairs_tested + 1
            
            if        (ones[i, 2] >  zeros[j, 2]) { 
                conc <- conc + 1 
            } else if (ones[i, 2] == zeros[j, 2]){ 
                ties <- ties + 1 
            } else { 
                disc <- disc + 1 
            } # end if-else
        } # end inner for
    } # end outer for
    
    # Calculate concordance, discordance and ties
    concordance <- conc / pairs_tested
    discordance <- disc / pairs_tested
    ties_perc   <- ties / pairs_tested
    n           <- nrow(fitted)
    
    # index
    # http://support.sas.com/kb/45/767.html
    # http://support.sas.com/documentation/cdl/en/statug/66103/HTML/default/viewer.htm#statug_surveylogistic_details64.htm
    return(
        list(
            "Concordance" = concordance,
            "Discordance" = discordance,
            "Tied"        = ties_perc,
            "Pairs"       = pairs_tested,
            
            ### Somers' D
            "Somers D"    = (concordance - discordance),
            
            ### Goodman-Kruskal Gamma
            "gamma"       = (concordance - discordance) / (concordance + discordance),
            
            ### Kendall's Tau-a
            "tau-a"       = (conc - disc) / (0.5 * n * (n - 1)),
            
            ### c-statistics
            "c"           = auc(y_true, y_score)
        ) # end list
    ) # end return
} # end func
```


```{r}
y_true = c(train_labels[, 2], test_labels[, 2])
y_pred = apply(rbind(train_data, test_data), 1, function(x){
    x %>% rbind %>% predict_classes(model, .)
}) # end apply

concordance(y_true, y_pred)
```


```{r}
df = data.frame(cbind(y_true, y_pred))
colnames(df) = c('obs','fitted')
rocobj = roc(df$obs, df$fitted)

options(repr.plot.height = 4, repr.plot.width = 4)
plot(rocobj, 
     print.auc=TRUE, auc.polygon=TRUE, 
     #grid=c(0.1, 0.2), grid.col=c("grey90", "grey90"), 
     max.auc.polygon=TRUE,
     auc.polygon.col="steelblue",
     print.thres=FALSE)
```




